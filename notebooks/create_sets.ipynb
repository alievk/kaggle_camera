{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import exifread\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_root = Path('../data')\n",
    "train_root = data_root / 'train_orig'\n",
    "flickr_root = data_root / 'external/flickr_images_orig'\n",
    "ext_valid_root = data_root / 'external/val_images'\n",
    "sets_root = data_root / 'sets'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train and validation splits from the official dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/train_orig/Samsung-Galaxy-Note3\n",
      "../data/train_orig/LG-Nexus-5x\n",
      "../data/train_orig/Samsung-Galaxy-S4\n",
      "../data/train_orig/iPhone-4s\n",
      "../data/train_orig/HTC-1-M7\n",
      "../data/train_orig/iPhone-6\n",
      "../data/train_orig/Motorola-Droid-Maxx\n",
      "../data/train_orig/Sony-NEX-7\n",
      "../data/train_orig/Motorola-X\n",
      "../data/train_orig/Motorola-Nexus-6\n"
     ]
    }
   ],
   "source": [
    "train_split = 0.8\n",
    "\n",
    "np.random.seed(2018)\n",
    "\n",
    "image_models = []\n",
    "image_paths = []\n",
    "#image_sizes = []\n",
    "\n",
    "fix_path = lambda p: p.relative_to(train_root)\n",
    "\n",
    "m = 0\n",
    "for class_dir in train_root.iterdir():\n",
    "    if not class_dir.is_dir():\n",
    "        continue\n",
    "    print(class_dir)\n",
    "    image_paths1 = [path for path in class_dir.glob('*.jpg')]\n",
    "    image_paths1.extend([path for path in class_dir.glob('*.JPG')])\n",
    "    n_images = len(image_paths1)\n",
    "    assert n_images == 275, n_images\n",
    "    \n",
    "    #for img_path in image_paths1:\n",
    "    #    image_sizes.append(cv2.imread(str(img_path)).shape[:2])\n",
    "    \n",
    "    image_paths1 = [fix_path(p) for p in image_paths1]\n",
    "    image_paths.extend(image_paths1)\n",
    "    \n",
    "    image_models.extend([m] * n_images)\n",
    "    m += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_paths = []\n",
    "train_image_sizes = []\n",
    "valid_image_paths = []\n",
    "valid_image_sizes = []\n",
    "\n",
    "for m in range(10):\n",
    "    inds = np.argwhere(np.array(image_models) == m).squeeze()\n",
    "    inds = np.random.permutation(inds)\n",
    "    image_paths1 = [image_paths[i] for i in inds]\n",
    "    image_sizes1 = [image_sizes[i] for i in inds]\n",
    "    n_images = len(inds)\n",
    "    n_train = int(n_images * train_split)\n",
    "    train_image_paths.extend(image_paths1[:n_train])\n",
    "    train_image_sizes.extend(image_sizes1[:n_train])\n",
    "    valid_image_paths.extend(image_paths1[n_train:])\n",
    "    valid_image_sizes.extend(image_sizes1[n_train:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df =\\\n",
    "pd.DataFrame({'fname': train_image_paths, \n",
    "              'h': [s[0] for s in train_image_sizes], \n",
    "              'w': [s[1] for s in train_image_sizes]})\n",
    "train_df.to_csv(str(sets_root / 'train.csv'), index=None)\n",
    "\n",
    "valid_df =\\\n",
    "pd.DataFrame({'fname': valid_image_paths, \n",
    "              'h': [s[0] for s in valid_image_sizes],\n",
    "              'w': [s[1] for s in valid_image_sizes]})\n",
    "valid_df.to_csv(str(sets_root / 'valid.csv'), index=None)\n",
    "\n",
    "pd.concat([train_df, valid_df]).to_csv(str(sets_root / 'trainval.csv'), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>h</th>\n",
       "      <th>w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Samsung-Galaxy-Note3/(GalaxyN3)166.jpg</td>\n",
       "      <td>2322</td>\n",
       "      <td>4128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Samsung-Galaxy-Note3/(GalaxyN3)100.jpg</td>\n",
       "      <td>4128</td>\n",
       "      <td>2322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Samsung-Galaxy-Note3/(GalaxyN3)170.jpg</td>\n",
       "      <td>4128</td>\n",
       "      <td>2322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Samsung-Galaxy-Note3/(GalaxyN3)207.jpg</td>\n",
       "      <td>4128</td>\n",
       "      <td>2322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Samsung-Galaxy-Note3/(GalaxyN3)97.jpg</td>\n",
       "      <td>4128</td>\n",
       "      <td>2322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    fname     h     w\n",
       "0  Samsung-Galaxy-Note3/(GalaxyN3)166.jpg  2322  4128\n",
       "1  Samsung-Galaxy-Note3/(GalaxyN3)100.jpg  4128  2322\n",
       "2  Samsung-Galaxy-Note3/(GalaxyN3)170.jpg  4128  2322\n",
       "3  Samsung-Galaxy-Note3/(GalaxyN3)207.jpg  4128  2322\n",
       "4   Samsung-Galaxy-Note3/(GalaxyN3)97.jpg  4128  2322"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(str(sets_root / 'train.csv'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fname', 'h', 'w']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[c for c in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create validation dataset from the FLICKR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('htc_m7', 745),\n",
       " ('iphone_4s', 436),\n",
       " ('iphone_6', 546),\n",
       " ('moto_maxx', 543),\n",
       " ('moto_x', 344),\n",
       " ('nexus_5x', 329),\n",
       " ('nexus_6', 649),\n",
       " ('samsung_note3', 803),\n",
       " ('samsung_s4', 1131),\n",
       " ('sony_nex7', 552)]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flickr_paths = []\n",
    "with open(str(flickr_root / 'good_jpgs_refined')) as f:\n",
    "    for path in [l.strip() for l in f.readlines()]:\n",
    "        if not (flickr_root/Path(path)).exists():\n",
    "            print('{} not found'.format(path))\n",
    "        else:\n",
    "            flickr_paths.append(path)\n",
    "\n",
    "flickr_models, count = np.unique([Path(p).parts[0] for p in flickr_paths], return_counts=True)\n",
    "[m for m in zip(list(flickr_models), list(count))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low_quality = []\n",
    "with open(str(flickr_root / 'low-quality.txt')) as f:\n",
    "    for path in [l.strip() for l in f.readlines()]:\n",
    "        low_quality.append(path.split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flickr_train_split = 0.8\n",
    "flickr_max_model_samples = 500 #min(count)\n",
    "print('max samples', flickr_max_model_samples)\n",
    "\n",
    "np.random.seed(2018)\n",
    "\n",
    "flickr_train_set = []\n",
    "flickr_valid_set = []\n",
    "\n",
    "#flickr_fix_path = lambda p: (flickr_root / p).relative_to('..')\n",
    "\n",
    "flickr_paths_m = defaultdict(list)\n",
    "for path in flickr_paths:\n",
    "    flickr_paths_m[Path(path).parts[0]].append(path)\n",
    "\n",
    "for m, paths in flickr_paths_m.items():\n",
    "    paths = np.random.permutation(paths)[:min(flickr_max_model_samples, len(paths))]\n",
    "    n_images = len(paths)\n",
    "    train_paths = paths[:int(n_images * flickr_train_split)]\n",
    "    valid_paths = paths[int(n_images * flickr_train_split):]\n",
    "    flickr_train_set.extend(train_paths)\n",
    "    flickr_valid_set.extend(valid_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_manip = [int(p in low_quality) for p in flickr_train_set]\n",
    "valid_manip = [int(p in low_quality) for p in flickr_valid_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['fname', 'manip']\n",
    "pd.DataFrame(dict(zip(columns, [flickr_train_set, train_manip])), columns=columns).to_csv(\n",
    "    str(sets_root / 'flickr_train.csv'), index=None)\n",
    "pd.DataFrame(dict(zip(columns, [flickr_valid_set, valid_manip])), columns=columns).to_csv(\n",
    "    str(sets_root / 'flickr_valid.csv'), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract EXIF"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Extract EXIF and save\n",
    "\n",
    "exif_per_model = defaultdict(list)\n",
    "for model in flickr_root.iterdir():\n",
    "    if not model.is_dir():\n",
    "        continue\n",
    "    print(model)\n",
    "    for p in model.iterdir():\n",
    "        if '.jpg' not in str(p) and '.JPG' not in str(p):\n",
    "            print('skip', str(p))\n",
    "            continue\n",
    "        with open(str(p), 'rb') as fh:\n",
    "            _tags = exifread.process_file(fh)\n",
    "            tags = {k: v for k, v in _tags.items() if 'thumbnail' not in k.lower()}\n",
    "            exif_per_model[str(model.stem)].append((str(p), tags))\n",
    "            \n",
    "pickle.dump(exif_per_model, open(str(flickr_root / 'exif_per_model.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exif_per_model = pickle.load(open(str(flickr_root / 'exif_per_model.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_props(exif_per_model, prop, unique=True):\n",
    "    out = {}\n",
    "    for model, exifs in exif_per_model.items():\n",
    "        props = [exif[prop].__str__() for _, exif in exifs if prop in exif]\n",
    "        out[model] = set(props) if unique else props\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = get_props(exif_per_model, 'Image Software', unique=False)\n",
    "for k, v in props.items():\n",
    "    print('='*3, k, '='*3)\n",
    "    for vv, count in zip(*np.unique(v, return_counts=1)):\n",
    "        print(vv, 'x', count)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nexus_5x_sea = (flickr_root / 'nexus_5x_sea').read_text().splitlines()\n",
    "good_jpgs_refined = []\n",
    "fout = open(str(Path(flickr_root / 'good_jpgs_refined')), 'w')\n",
    "for p in flickr_paths:\n",
    "    if Path(p).parts[0] == 'nexus_5x' and Path(p).stem in nexus_5x_sea:\n",
    "        continue\n",
    "    fout.write(p + '\\n')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bad_nexus_5x = []\n",
    "for f, e in exif_per_model['nexus_5x']:\n",
    "    if 'Image Software' in e and str(e['Image Software']) == 'bullhead-user 6.0 MDB08I 2340339 release-keys':\n",
    "        #print(f)\n",
    "        bad_nexus_5x.append(Path(f).relative_to(flickr_root))\n",
    "\n",
    "bad_nexus_5x = np.random.permutation(bad_nexus_5x)[:-50]\n",
    "print(len(bad_nexus_5x))\n",
    "good_jpgs_refined = [p for p in flickr_paths if Path(p).__str__() not in bad_nexus_5x.__str__()]\n",
    "print(len(good_jpgs_refined), len(flickr_paths))\n",
    "print(Path(flickr_paths[0]).__str__())\n",
    "with open(str(Path(flickr_root / 'good_jpgs_refined')),'w') as fout:\n",
    "    [fout.write(line+'\\n') for line in good_jpgs_refined]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exif_per_model['iphone_4s'][0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "orig_img_sizes = pickle.load(open(str(train_root / 'img_sizes.pkl'), 'rb'))\n",
    "\n",
    "ok_sized = defaultdict(list)\n",
    "\n",
    "# -> it's not reliable to read image size from EXIF\n",
    "\n",
    "# for _model, exifs in exif_per_model.items():\n",
    "#     for path, exif in exifs:\n",
    "#         if 'EXIF ExifImageWidth' not in exif.keys() or 'EXIF ExifImageLength' not in exif.keys():\n",
    "#             sz = list(cv2.imread(str(path)).shape[:2])\n",
    "#         else:\n",
    "#             sz = [int(exif['EXIF ExifImageWidth'].__str__()), int(exif['EXIF ExifImageLength'].__str__())]\n",
    "#         model = name_map[_model]\n",
    "#         if sz in orig_img_sizes[model]:\n",
    "#             ok_sized[model].append(path)\n",
    "\n",
    "# read image size with opencv\n",
    "for model_dir in flickr_root.iterdir():\n",
    "    if not model_dir.is_dir():\n",
    "        continue\n",
    "    print(model_dir)\n",
    "    model = name_map[model_dir.stem]\n",
    "    imgs = [p for p in model_dir.glob('*.jpg')]\n",
    "    imgs.extend([p for p in model_dir.glob('*.JPG')])\n",
    "    for p in imgs:\n",
    "        sz = cv2.imread(str(p)).shape[:2]\n",
    "        if list(sz) in orig_img_sizes[model]:\n",
    "            ok_sized[model].append(p)\n",
    "    print('{}: {}/{}'.format(model, len(ok_sized[model]), len(imgs)))\n",
    "    \n",
    "with open(str(flickr_root / 'good_jpegs_my.txt'), 'w') as fh:\n",
    "for paths in ok_sized.values():\n",
    "    for p in paths:\n",
    "        fh.write(str(p.relative_to(flickr_root))+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = [Path(p).parts[0] for p in low_quality]\n",
    "np.unique(m,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle camera env",
   "language": "python",
   "name": "kaggle_camera_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
